import os
import requests
from dotenv import load_dotenv
from bs4 import BeautifulSoup
from IPython.display import Markdown, display
from openai import OpenAI

load_dotenv(override=True)
api_key = os.getenv('OPENAI_API_KEY')
openai = OpenAI()

# get the string for the website that we want to search and scrape
website_str = input('what site whoud you like to search? ') #https://yle.fi/news
##TODO what to do if the url is garbage

# get the word class that the user wants to be listed
word_class = input('What kind of word class would you like to list? Please select between "NOUNS", "VERBS" or "ADJECTIVES": ')
#TODO if the input is anything else

# Some websites need you to use proper headers when fetching them.
# The headers identify us as best as can be done as real users rather than python code
# To find a header - google the webpage, press ctrl+shift+i to enter developer tools
#                   - go to network tab
#                   - reload the page to get some activity
#                   - click on any resource to see details
#                   - the header we are after is request header: user agent
headers = {
    "User-Agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/130.0.0.0 Safari/537.36"
}

# Create this Website object from the given url using the BeautifulSoup library
class Website:
    def __init__(self, url):
        self.url = url
        response = requests.get(url, headers=headers)
        soup = BeautifulSoup(response.content, 'html.parser')
        self.title = soup.title.string if soup.title else "No title found"
        for irrelevant in soup.body(["script", "style", "img", "input"]):
            irrelevant.decompose()
        self.text = soup.body.get_text(separator="\n", strip=True)

# instantiate the website
website = Website(website_str)

#Create the prompts
system_prompt = "you are a language teacher"
user_prompt = f"Find all finnish {word_class} in the text and give me their list together with their translation into English - {website.text}"

# Make the messages list
messages = [
    {"role":"system","content":system_prompt},
    {"role":"user","content":user_prompt}           
] 

# Call OpenAI
def list_of_words(url):
    response = openai.chat.completions.create(
        model = "gpt-4o-mini",
        messages = messages
    )
    return response.choices[0].message.content

# print the result
print(list_of_words(website_str))

